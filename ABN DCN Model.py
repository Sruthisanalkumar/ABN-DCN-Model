# -*- coding: utf-8 -*-
"""Copy of  DCN_100x_2022.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14wPinMwzGwWamYZ5cH5OnMR2VfmYH4w6
"""

from google.colab import drive
drive.mount('/content/drive')

# import torch
# torch.cuda.is_available()

# import os
# # importing sys
import sys  
# # # adding models to the system path
sys.path.insert(0, '/content/drive/MyDrive/histopathology/codes/ABN/')
import models_new
# from models import dcn as customized_models
from models_new import imagenet as customized_models

!pip install "torch==1.7.0" "torchvision==0.8.0"

models_new

!pip install timm==0.4.12

sys.path.insert(0, '/content/drive/MyDrive/histopathology/codes')
from utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig

from __future__ import print_function

import argparse
import os
import shutil
import time
import random

import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data as data
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import matplotlib.pyplot as plt
import numpy as np
import cv2
import pandas as pd
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.metrics import classification_report 
from google.colab.patches import cv2_imshow
# import torchvision.models as models
# import models.imagenet as customized_models

# Models
default_model_names = sorted(name for name in models_new.__dict__
    if name.islower() and not name.startswith("__")
    and callable(models_new.__dict__[name]))

default_model_names

customized_models_names = sorted(name for name in customized_models.__dict__
    if name.islower() and not name.startswith("__")
    and callable(customized_models.__dict__[name]))

customized_models_names

for name in customized_models.__dict__:
    if name.islower() and not name.startswith("__") and callable(customized_models.__dict__[name]):
        models_new.__dict__[name] = customized_models.__dict__[name]

model_names = default_model_names+customized_models_names
# Parse arguments
parser = argparse.ArgumentParser(description='PyTorch BreakHis Training')
# model_names=customized_models_names[52]

model_names

# Datasets
# parser.add_argument('-d', '--dataset', default='/content/drive/My Drive/histopathology/dataset/40x', type=str)
parser.add_argument('-d', '--dataset', default='/content/drive/My Drive/histopathology/dataset/100x', type=str)
parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',
                    help='number of data loading workers (default: 4)')
# Optimization options
parser.add_argument('--epochs', default=2, type=int, metavar='N',
                    help='number of total epochs to run')
parser.add_argument('--start-epoch', default=0, type=int, metavar='N',
                    help='manual epoch number (useful on restarts)')
parser.add_argument('--train-batch', default=256, type=int, metavar='N',
                    help='train batchsize (default: 256)')
parser.add_argument('--test-batch', default=200, type=int, metavar='N',
                    help='test batchsize (default: 200)')
parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,
                    metavar='LR', help='initial learning rate')
parser.add_argument('--drop', '--dropout', default=0, type=float,
                    metavar='Dropout', help='Dropout ratio')
parser.add_argument('--schedule', type=int, nargs='+', default=[150, 225],
                        help='Decrease learning rate at these epochs.')
parser.add_argument('--gamma', type=float, default=0.1, help='LR is multiplied by gamma on schedule.')
parser.add_argument('--momentum', default=0.9, type=float, metavar='M',
                    help='momentum')
parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,
                    metavar='W', help='weight decay (default: 1e-4)')
# Checkpoints
parser.add_argument('-c', '--checkpoint', default='checkpoint', type=str, metavar='PATH',
                    help='path to save checkpoint (default: checkpoint)')
parser.add_argument('--resume', default='', type=str, metavar='PATH',
                    help='path to latest checkpoint (default: none)')
# Architecture
parser.add_argument('--arch', '-a', metavar='ARCH', default='dcn',
                    choices=model_names,
                    help='model architecture: ' +
                        ' | '.join(model_names) +
                        ' (default: dcn)')
# parser.add_argument('--depth', type=int, default=29, help='Model depth.')
# parser.add_argument('--cardinality', type=int, default=32, help='ResNet cardinality (group).')
# parser.add_argument('--base-width', type=int, default=4, help='ResNet base width.')
# parser.add_argument('--widen-factor', type=int, default=4, help='Widen factor. 4 -> 64, 8 -> 128, ...')
parser.add_argument('--block', type=str, default='DCNBlock', help='the building block for dcn')
parser.add_argument('--num_classes', type=int, default=2, help='num_classes')
# Miscs
parser.add_argument('--manualSeed', type=int, help='manual seed')
parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',
                    help='evaluate model on validation set')
parser.add_argument('--pretrained', dest='pretrained', action='store_true',
                    help='use pre-trained model')
#Device options
# parser.add_argument('--gpu-id', default='0', type=str,
#                     help='id(s) for CUDA_VISIBLE_DEVICES')

import sys
sys.argv=['']
del sys
args = parser.parse_args()
state = {k: v for k, v in args._get_kwargs()}

# # Use CUDA
# os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu_id
# use_cuda = torch.cuda.is_available()

# Random seed
if args.manualSeed is None:
    args.manualSeed = random.randint(1, 10000)
random.seed(args.manualSeed)
torch.manual_seed(args.manualSeed)
# if use_cuda:
#     torch.cuda.manual_seed_all(args.manualSeed)

best_acc = 0  # best test accuracy

# from google.colab.patches import cv2_imshow
from matplotlib.pyplot import imshow

inv_normalize =  transforms.Normalize(
    mean=[-0.4302/0.2361, -0.4575/0.2347, -0.4539/0.2432],
    std=[1/0.2361, 1/0.2347, 1/0.2432]
)

def main():
    global best_acc
    start_epoch = args.start_epoch  # start from epoch 0 or last checkpoint epoch

    if not os.path.isdir(args.checkpoint):
        mkdir_p(args.checkpoint)

    # Data loading code
    traindir = os.path.join(args.dataset, 'train')
    valdir = os.path.join(args.dataset, 'test')
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                     std=[0.229, 0.224, 0.225])

    train_loader = torch.utils.data.DataLoader(
        datasets.ImageFolder(traindir, transforms.Compose([
            transforms.RandomSizedCrop(256),
            transforms.RandomRotation(degrees=(-25, 25)),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            normalize,
        ])),
        batch_size=args.train_batch, shuffle=True,
        num_workers=args.workers, pin_memory=True)

    val_loader = torch.utils.data.DataLoader(
        datasets.ImageFolder(valdir, transforms.Compose([
            transforms.Scale(256),
            transforms.CenterCrop(256),
            transforms.ToTensor(),
            normalize,
        ])),
        batch_size=args.test_batch, shuffle=False,
        num_workers=args.workers, pin_memory=True)

    print("=> creating model '{}'".format(args.arch))
    if args.arch.startswith('dcn'):
       model = models_new.__dict__[args.arch](
                    block=args.block,
                    num_classes=args.num_classes,
                    
                )
    else:
        model = models_new.__dict__[args.arch](num_classes=args.num_classes)

    #cudnn.benchmark = True
    print('Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))
    from PIL import ImageFile
    ImageFile.LOAD_TRUNCATED_IMAGES = True

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)

    # Resume
    title = 'dcn-' + args.arch
    if args.resume:
        # Load checkpoint.
        print('==> Resuming from checkpoint..')
        assert os.path.isfile(args.resume), 'Error: no checkpoint directory found!'
        args.checkpoint = os.path.dirname(args.resume)
        checkpoint = torch.load(args.resume)
        best_acc = checkpoint['best_acc']
        start_epoch = checkpoint['epoch']
        model.load_state_dict(checkpoint['state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        logger = Logger(os.path.join(args.checkpoint, 'log.txt'), title=title, resume=True)
    else:
        logger = Logger(os.path.join(args.checkpoint, 'log.txt'), title=title)
        logger.set_names(['Train Loss', 'Valid Loss'])


    if args.evaluate:
        print('\nEvaluation only')
        test_loss, test_acc = test(val_loader, model, criterion, start_epoch)
        print(' Test Loss:  %.8f, Test Acc:  %.2f' % (test_loss, test_acc))
        return

    # Train and val
    for epoch in range(start_epoch, args.epochs):
        adjust_learning_rate(optimizer, epoch)

        print('\nEpoch: [%d | %d] LR: %f' % (epoch + 1, args.epochs, state['lr']))

        train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch)
        test_loss, test_acc = test(val_loader, model, criterion, epoch)

        logger.append([train_loss, test_loss])
      

        # save model
        is_best = test_acc > best_acc
        best_acc = max(test_acc, best_acc)
        save_checkpoint({
                'epoch': epoch + 1,
                'state_dict': model.state_dict(),
                'acc': test_acc,
                'best_acc': best_acc,
                'optimizer' : optimizer.state_dict(),
            }, is_best, checkpoint=args.checkpoint)

    logger.close()
    savefig(os.path.join(args.checkpoint, 'log.jpg'))
    logger.plot()
    print('Best acc:')
    print(best_acc)
    incorrect_examples = []
    incorrect_labels = []
    incorrect_pred = []
    preds=[]
    true=[]
    image=[]
    pred_wrong=[]
    true_wrong=[]
    encoder = {}
    transform = transforms.Compose([transforms.Grayscale()])
    dataset =  datasets.ImageFolder(traindir, transform=transform)
    classes = dataset.classes
    for i in range(len(classes)):
       encoder[i] = classes[i]  
    model.eval()
    for data,target in val_loader:
         print(len(data))
         print(len(target))
         output = model(data) # shape = torch.Size([batch_size, 10])
         output,x,[x1,x2,x3] = model(data)
         pred= torch.argmax(output,dim=1, keepdim=True) #pred will be a 2d tensor of shape [batch_size,1]
         pred = np.reshape(pred,(len(pred),1))
         target = np.reshape(target,(len(pred),1))
         for i in range(len(pred)):
            preds.append(pred[i])
            true.append(target[i])
            if(pred[i]!=target[i]):
                pred_wrong.append(pred[i])
                true_wrong.append(target[i])
                image.append(data[i])
    fig,axes = plt.subplots(figsize=(14, 10), nrows = 4, ncols=3)
    print(classification_report(true, pred))
    for ax in axes.flatten():
        a = random.randint(0,len(pred_wrong)-1)
        image1=image[a]
        if inv_normalize !=None:
            image1 = inv_normalize(image1)
            image1 = image1.numpy().transpose(1,2,0)
            im = ax.imshow(image1)
            ax.set_title("misclassified images")
            ax.axis('off')
    plt.show()

def train(train_loader, model, criterion, optimizer, epoch):
    # switch to train mode
    model.train()

    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()
    top1 = AverageMeter()
    top5 = AverageMeter()
    end = time.time()

    bar = Bar('Processing', max=len(train_loader))
    for batch_idx, (inputs, targets) in enumerate(train_loader):
        # measure data loading time
        data_time.update(time.time() - end)

        # if use_cuda:
        # inputs, targets = inputs, targets(async=True)
        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)
        # compute output
        att_outputs, outputs, _  = model(inputs)
        att_loss = criterion(att_outputs, targets)
        per_loss = criterion(outputs, targets)
        loss = att_loss + per_loss

       

        # measure accuracy and record loss
        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 2))
        losses.update(loss.data, inputs.size(0))
        top1.update(prec1, inputs.size(0))
        top5.update(prec5, inputs.size(0))

        # compute gradient and do SGD step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        # plot progress
        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(
                    batch=batch_idx + 1,
                    size=len(train_loader),
                    data=data_time.val,
                    bt=batch_time.val,
                    total=bar.elapsed_td,
                    eta=bar.eta_td,
                    loss=losses.avg,
                    top1=top1.avg,
                    top5=top5.avg,
                    )
        bar.next()
    bar.finish()
    return (losses.avg, top1.avg)

def test(val_loader, model, criterion, epoch):
    global best_acc

    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()
    top1 = AverageMeter()
    top5 = AverageMeter()

    # switch to evaluate mode
    model.eval()

    end = time.time()
    bar = Bar('Processing', max=len(val_loader))
    for batch_idx, (inputs, targets) in enumerate(val_loader):
        # measure data loading time
        data_time.update(time.time() - end)

        # if use_cuda:
            # inputs, targets = inputs, targets
        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)

        # compute output
        outputs,x,[x1,x2,x3]  = model(inputs)
        loss = criterion(outputs, targets)

        # measure accuracy and record loss
        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 2))
        losses.update(loss.data, inputs.size(0))
        top1.update(prec1, inputs.size(0))
        top5.update(prec5, inputs.size(0))

        # measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        # plot progress
        bar.suffix  = '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(
                    batch=batch_idx + 1,
                    size=len(val_loader),
                    data=data_time.avg,
                    bt=batch_time.avg,
                    total=bar.elapsed_td,
                    eta=bar.eta_td,
                    loss=losses.avg,
                    top1=top1.avg,
                    top5=top5.avg,
                    )
        bar.next()
    bar.finish()
    return (losses.avg, top1.avg)

def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):
    filepath = os.path.join(checkpoint, filename)
    torch.save(state, filepath)
    if is_best:
        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))

def adjust_learning_rate(optimizer, epoch):
    global state
    if epoch in args.schedule:
        state['lr'] *= args.gamma
        for param_group in optimizer.param_groups:
            param_group['lr'] = state['lr']

if __name__ == '__main__':
    main()

# Commented out IPython magic to ensure Python compatibility.
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
image = Image.open('/content/drive/My Drive/histopathology/dataset/100x/test/malignant/SOB_M_MC-14-12773-100-002.png')
image = np.array(image)
plt.imshow(image)

class DCNBlock(nn.Module):
    def __init__(self,ni,nf):
        super(DCNBlock, self).__init__()
        self.layer1 = conv_block(ni,nf)
        self.layer2 = conv_block(nf,ni,size=1)
        self.layer3 = conv_block(ni,nf)

    def forward(self, x):
        # residual = x
        out = self.layer1(x)
        out = self.layer2(out)
        out=self.layer3(out)
        return out

import torch
import sys
# sys.path.append("attention_branch_network")
from models_new.imagenet import dcn

model = dcn(DCNBlock,num_classes=2)

model_path = "checkpoint/model_best.pth.tar"
checkpoint = torch.load(model_path)
model.load_state_dict(checkpoint['state_dict'])

model.eval();

import cv2

image_resized = cv2.resize(image, (256,256))


mean = np.array([[[0.485, 0.456, 0.406]]])
std = np.array([[[0.229, 0.224, 0.225]]])
input = image_resized / 255.0
input = (input - mean) / std


input = np.transpose(input, (2, 0, 1))
input = input[None, :, :, :]
input = torch.Tensor(input)

input = torch.autograd.Variable(input)
input.shape

# Input test-data into the network
# import matplotlib.pyplot as plt
import matplotlib.cm as cm
with torch.no_grad():
   ax, rx, atts = model(input)

att, _, _ = atts
# print (att)
print(att.shape)
print(rx.shape)
att = att.cpu().detach().numpy()[0][0]

att = cv2.resize(att, (256, 256), interpolation=cv2.INTER_LINEAR)


# Plot results
fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(3 * 5, 5))
  
## Input image
ax0.imshow(image_resized)
ax0.set_title("Input image")

## Attention map
x=ax1.imshow(att, cmap='jet', vmin=att.min(), vmax=att.max())
ax1.set_title("Attention map")


## Input image + attention map
extent = 0, 256, 0, 256
ax2.imshow(image_resized, extent=extent)
z=ax2.imshow(att, cmap='jet', alpha=0.4, extent=extent, vmin=att.min(), vmax=att.max())
ax2.set_title("Input image + attention map")
plt.colorbar(z,shrink=0.75)


plt.show()

rx_array = rx.cpu().detach().numpy()[0]
rx_pred = np.argmax(rx_array)
print("Prediction from classification branch : ", rx_pred)

ax_array = ax.cpu().detach().numpy()[0]
ax_pred = np.argmax(ax_array)
print("Prediction from attention branch : ", ax_pred)

from PIL import Image
import numpy as np
import sys
import os
import csv
import cv2
import matplotlib.cm as cm
dataset_directory = '/content/drive/My Drive/histopathology/dataset/100x/test/benign'
import glob
from PIL import Image 
items=[]
for root, dirs, subdirs in os.walk(dataset_directory, topdown=False):
    for subdirs in dirs:
        print(os.path.join(root, subdirs))
    for name in subdirs:
        print(os.path.join(root, name))
        image = cv2.imread(os.path.join(root, name))
        image_resized = cv2.resize(image, (256,256))
        mean = np.array([[[0.485, 0.456, 0.406]]])
        std = np.array([[[0.229, 0.224, 0.225]]])
        input = image_resized / 255.0
        input = (input - mean) / std
        input = np.transpose(input, (2, 0, 1))
        input = input[None, :, :, :]
        input = torch.Tensor(input)
        input = torch.autograd.Variable(input)
  #   input.shape
        with torch.no_grad():
            ax, rx, atts = model(input)
        att, _, _ = atts
        att = att.cpu().detach().numpy()[0][0]
        att = cv2.resize(att, (256, 256), interpolation=cv2.INTER_LINEAR)
  #   # Plot results
        fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(3 * 5, 5)) 
  #  ## Input image
        ax0.imshow(image_resized)
        ax0.set_title("Input image")
  #   ## Attention map
        x=ax1.imshow(att, cmap='jet', vmin=att.min(), vmax=att.max())
        ax1.set_title("Attention map")
  #   ## Input image + attention map
        extent = 0, 256, 0, 256
        ax2.imshow(image_resized, extent=extent)
        z=ax2.imshow(att, cmap='jet', alpha=0.4, extent=extent, vmin=att.min(), vmax=att.max())
  #   # plt.colorbar(z, cmap=cm.jet,min=0.0,max=2.0, orientation="vertical",shrink=.75)
        ax2.set_title("Input image + attention map")
        plt.colorbar(z,shrink=0.75)
        plt.show()

from PIL import Image
import numpy as np
import sys
import os
import csv
import cv2
import matplotlib.cm as cm
dataset_directory = '/content/drive/My Drive/histopathology/dataset/100x/test/malignant'
import glob
from PIL import Image 
items=[]
for root, dirs, subdirs in os.walk(dataset_directory, topdown=False):
    for subdirs in dirs:
        print(os.path.join(root, subdirs))
    for name in subdirs:
        print(os.path.join(root, name))
        image = cv2.imread(os.path.join(root, name))
        image_resized = cv2.resize(image, (256,256))
        mean = np.array([[[0.485, 0.456, 0.406]]])
        std = np.array([[[0.229, 0.224, 0.225]]])
        input = image_resized / 255.0
        input = (input - mean) / std
        input = np.transpose(input, (2, 0, 1))
        input = input[None, :, :, :]
        input = torch.Tensor(input)
        input = torch.autograd.Variable(input)
  #   input.shape
        with torch.no_grad():
            ax, rx, atts = model(input)
        att, _, _ = atts
        att = att.cpu().detach().numpy()[0][0]
        att = cv2.resize(att, (256, 256), interpolation=cv2.INTER_LINEAR)
  #   # Plot results
        fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(3 * 5, 5)) 
  #  ## Input image
        ax0.imshow(image_resized)
        ax0.set_title("Input image")
  #   ## Attention map
        x=ax1.imshow(att, cmap='jet', vmin=att.min(), vmax=att.max())
        ax1.set_title("Attention map")
  #   ## Input image + attention map
        extent = 0, 256, 0, 256
        ax2.imshow(image_resized, extent=extent)
        z=ax2.imshow(att, cmap='jet', alpha=0.4, extent=extent, vmin=att.min(), vmax=att.max())
        ax2.set_title("Input image + attention map")
        plt.colorbar(z,shrink=0.75)
        plt.show()
